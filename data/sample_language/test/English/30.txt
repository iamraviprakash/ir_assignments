The two that really stand out are,

1.) "Markov decision problems" -- a term that I use broadly to include both discrete time and state spaces (what people normally mean when they say "Markov Decision Problem" (MDP)), and with continuous time and state spaces (which people normally call "optimal control").